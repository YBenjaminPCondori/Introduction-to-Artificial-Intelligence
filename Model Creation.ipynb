{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4dc324e1",
   "metadata": {},
   "source": [
    "# London Crime Conv1D Classifier\n",
    "Predicting **Crime type** using TensorFlow/Keras Conv1D Neural Network\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baba850f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-04 20:58:51.734393: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-12-04 20:58:51.734763: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-12-04 20:58:51.782836: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-12-04 20:58:53.313762: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-12-04 20:58:53.314236: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-12-04 20:58:53.313762: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-12-04 20:58:53.314236: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n"
     ]
    }
   ],
   "source": [
    "# Libraries\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder, OneHotEncoder\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn import metrics\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Input, Dropout, BatchNormalization\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.optimizers import Adamax\n",
    "from tensorflow import keras\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3a46835",
   "metadata": {},
   "source": [
    "## Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9871ba64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Crime ID</th>\n",
       "      <th>Month</th>\n",
       "      <th>Reported by</th>\n",
       "      <th>Falls within</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Location</th>\n",
       "      <th>LSOA code</th>\n",
       "      <th>LSOA name</th>\n",
       "      <th>Crime type</th>\n",
       "      <th>Last outcome category</th>\n",
       "      <th>Context</th>\n",
       "      <th>source_file</th>\n",
       "      <th>source_folder</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5a10b2cf8fa37fbf3933f66319f1c2ce76ef9697e19442...</td>\n",
       "      <td>2024-12</td>\n",
       "      <td>City of London Police</td>\n",
       "      <td>City of London Police</td>\n",
       "      <td>-0.105965</td>\n",
       "      <td>51.518514</td>\n",
       "      <td>On or near Further/Higher Educational Building</td>\n",
       "      <td>E01000916</td>\n",
       "      <td>Camden 027B</td>\n",
       "      <td>Robbery</td>\n",
       "      <td>Investigation complete; no suspect identified</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2024-12-city-of-london-street.csv</td>\n",
       "      <td>datasets</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>71ac2a8e6b747e5044b1bb5e8b93b8b13a09bf39649390...</td>\n",
       "      <td>2024-12</td>\n",
       "      <td>City of London Police</td>\n",
       "      <td>City of London Police</td>\n",
       "      <td>-0.111596</td>\n",
       "      <td>51.518281</td>\n",
       "      <td>On or near Chancery Lane</td>\n",
       "      <td>E01000914</td>\n",
       "      <td>Camden 028B</td>\n",
       "      <td>Other theft</td>\n",
       "      <td>Investigation complete; no suspect identified</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2024-12-city-of-london-street.csv</td>\n",
       "      <td>datasets</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>e5dc3c4e04ebc5285c57dabef730c271df889665252ed9...</td>\n",
       "      <td>2024-12</td>\n",
       "      <td>City of London Police</td>\n",
       "      <td>City of London Police</td>\n",
       "      <td>-0.112096</td>\n",
       "      <td>51.515942</td>\n",
       "      <td>On or near Nightclub</td>\n",
       "      <td>E01000914</td>\n",
       "      <td>Camden 028B</td>\n",
       "      <td>Robbery</td>\n",
       "      <td>Status update unavailable</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2024-12-city-of-london-street.csv</td>\n",
       "      <td>datasets</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2072389e40234ffec9830716e10ba0aa4ad91fbe282bf5...</td>\n",
       "      <td>2024-12</td>\n",
       "      <td>City of London Police</td>\n",
       "      <td>City of London Police</td>\n",
       "      <td>-0.112537</td>\n",
       "      <td>51.519582</td>\n",
       "      <td>On or near Gray'S Inn Square</td>\n",
       "      <td>E01000914</td>\n",
       "      <td>Camden 028B</td>\n",
       "      <td>Shoplifting</td>\n",
       "      <td>Status update unavailable</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2024-12-city-of-london-street.csv</td>\n",
       "      <td>datasets</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5fe3737ddf7156d6fb68bb3a2b54dcb1f7bc354f5f70e9...</td>\n",
       "      <td>2024-12</td>\n",
       "      <td>City of London Police</td>\n",
       "      <td>City of London Police</td>\n",
       "      <td>-0.111596</td>\n",
       "      <td>51.518281</td>\n",
       "      <td>On or near Chancery Lane</td>\n",
       "      <td>E01000914</td>\n",
       "      <td>Camden 028B</td>\n",
       "      <td>Theft from the person</td>\n",
       "      <td>Investigation complete; no suspect identified</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2024-12-city-of-london-street.csv</td>\n",
       "      <td>datasets</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Crime ID    Month  \\\n",
       "0  5a10b2cf8fa37fbf3933f66319f1c2ce76ef9697e19442...  2024-12   \n",
       "1  71ac2a8e6b747e5044b1bb5e8b93b8b13a09bf39649390...  2024-12   \n",
       "2  e5dc3c4e04ebc5285c57dabef730c271df889665252ed9...  2024-12   \n",
       "3  2072389e40234ffec9830716e10ba0aa4ad91fbe282bf5...  2024-12   \n",
       "4  5fe3737ddf7156d6fb68bb3a2b54dcb1f7bc354f5f70e9...  2024-12   \n",
       "\n",
       "             Reported by           Falls within  Longitude   Latitude  \\\n",
       "0  City of London Police  City of London Police  -0.105965  51.518514   \n",
       "1  City of London Police  City of London Police  -0.111596  51.518281   \n",
       "2  City of London Police  City of London Police  -0.112096  51.515942   \n",
       "3  City of London Police  City of London Police  -0.112537  51.519582   \n",
       "4  City of London Police  City of London Police  -0.111596  51.518281   \n",
       "\n",
       "                                         Location  LSOA code    LSOA name  \\\n",
       "0  On or near Further/Higher Educational Building  E01000916  Camden 027B   \n",
       "1                        On or near Chancery Lane  E01000914  Camden 028B   \n",
       "2                            On or near Nightclub  E01000914  Camden 028B   \n",
       "3                    On or near Gray'S Inn Square  E01000914  Camden 028B   \n",
       "4                        On or near Chancery Lane  E01000914  Camden 028B   \n",
       "\n",
       "              Crime type                          Last outcome category  \\\n",
       "0                Robbery  Investigation complete; no suspect identified   \n",
       "1            Other theft  Investigation complete; no suspect identified   \n",
       "2                Robbery                      Status update unavailable   \n",
       "3            Shoplifting                      Status update unavailable   \n",
       "4  Theft from the person  Investigation complete; no suspect identified   \n",
       "\n",
       "   Context                        source_file source_folder  \n",
       "0      NaN  2024-12-city-of-london-street.csv      datasets  \n",
       "1      NaN  2024-12-city-of-london-street.csv      datasets  \n",
       "2      NaN  2024-12-city-of-london-street.csv      datasets  \n",
       "3      NaN  2024-12-city-of-london-street.csv      datasets  \n",
       "4      NaN  2024-12-city-of-london-street.csv      datasets  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('2022_2025_city_of_london_street.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a34f71f4",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b7e27c30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop duplicates rows\n",
    "df.drop_duplicates(inplace=True)\n",
    "\n",
    "# Drop the Crime ID, source column, and source file columns since they contain duplicate information/administrative purposes when merging the datasets, or are identifiers.\n",
    "df.drop(columns=['Crime ID', 'Context', 'source_file', 'source_folder'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7c506111",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Strip column names\n",
    "# REASON: In some cases, when reading CSV files, extra spaces can be inadvertently added in the column names.\n",
    "# This can lead to issues when trying to access these columns later in the code, as the names won't match exactly.\n",
    "df.columns = df.columns.str.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "923cd1b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Fill missing numeric values using KNN imputation, which in this case is the GPS coordinates (Longitude, Latitude)\n",
    "numeric_cols = ['Longitude', 'Latitude']\n",
    "imputer = KNNImputer(n_neighbors=5)\n",
    "# Note: For production, fit the imputer on the training set only to avoid data leakage.\n",
    "df[numeric_cols] = imputer.fit_transform(df[numeric_cols])\n",
    "\n",
    "# Encode target values, so that the crime ('Crime type') can be used for classification, (LABELS) to (NUMERICAL RANGE)\n",
    "target_col = 'Crime type'\n",
    "encoder = LabelEncoder()\n",
    "\n",
    "df['target_encoded'] = encoder.fit_transform(df[target_col])\n",
    "num_classes = df['target_encoded'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8d9dd549",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Features: numeric and categorical\n",
    "categorical_cols = ['Reported by', 'Falls within', 'LSOA code', 'LSOA name']\n",
    "df_encoded = pd.get_dummies(df[categorical_cols])\n",
    "\n",
    "X = pd.concat([df[numeric_cols], df_encoded], axis=1).values\n",
    "y = to_categorical(df['target_encoded'], num_classes=num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9a385267",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize numeric features\n",
    "scaler = StandardScaler()\n",
    "X[:, :len(numeric_cols)] = scaler.fit_transform(X[:, :len(numeric_cols)])\n",
    "\n",
    "X = X.astype(\"float32\")  # ensure proper dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fecf214d",
   "metadata": {},
   "source": [
    "## Train/Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "065846b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68d5b8d6",
   "metadata": {},
   "source": [
    "## Model Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "618cb2d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │        <span style=\"color: #00af00; text-decoration-color: #00af00\">24,960</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">650</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">154</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │        \u001b[38;5;34m24,960\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_4 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             │           \u001b[38;5;34m650\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_5 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m)             │           \u001b[38;5;34m154\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">77,294</span> (301.93 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m77,294\u001b[0m (301.93 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">25,764</span> (100.64 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m25,764\u001b[0m (100.64 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">51,530</span> (201.29 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m51,530\u001b[0m (201.29 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m160/160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
      "\u001b[1m160/160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: 0.28582646250490773\n"
     ]
    }
   ],
   "source": [
    " \n",
    "model = Sequential()\n",
    "model.add(Input(X[1].shape))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(10))\n",
    "model.add(Dense(y.shape[1],activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam')\n",
    "model.fit(X_train,y_train,verbose=0,epochs=128)\n",
    "model.summary()\n",
    "pred = model.predict(X_test)\n",
    "pred = np.argmax(pred,axis=1)\n",
    "y_compare = np.argmax(y_test,axis=1) \n",
    "score = metrics.accuracy_score(y_compare, pred)\n",
    "print(\"Accuracy score: {}\".format(score))\n",
    "\n",
    "#path to where the file will be saved\n",
    "save_path = \"Model\"\n",
    "\n",
    "# save neural network structure to JSON (no weights)\n",
    "model_json = model.to_json()\n",
    "with open(os.path.join(save_path,\"network.json\"), \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "\n",
    "# save entire network to HDF5 (save everything, suggested)\n",
    "model.save(os.path.join(save_path,\"network.h5\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a9513f5",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a9c43281",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ad9dd215",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 2.0935 - val_loss: 2.2786\n",
      "Epoch 2/10\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 2.0935 - val_loss: 2.2786\n",
      "Epoch 2/10\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2.0904 - val_loss: 2.2782\n",
      "Epoch 3/10\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2.0904 - val_loss: 2.2782\n",
      "Epoch 3/10\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2.0899 - val_loss: 2.2794\n",
      "Epoch 4/10\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2.0899 - val_loss: 2.2794\n",
      "Epoch 4/10\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2.0898 - val_loss: 2.2795\n",
      "Epoch 5/10\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2.0898 - val_loss: 2.2795\n",
      "Epoch 5/10\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2.0894 - val_loss: 2.2802\n",
      "Epoch 6/10\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2.0894 - val_loss: 2.2802\n",
      "Epoch 6/10\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2.0894 - val_loss: 2.2802\n",
      "Epoch 7/10\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2.0894 - val_loss: 2.2802\n",
      "Epoch 7/10\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2.0894 - val_loss: 2.2808\n",
      "Epoch 8/10\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2.0894 - val_loss: 2.2808\n",
      "Epoch 8/10\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2.0891 - val_loss: 2.2806\n",
      "Epoch 9/10\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2.0891 - val_loss: 2.2806\n",
      "Epoch 9/10\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2.0892 - val_loss: 2.2812\n",
      "Epoch 10/10\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2.0892 - val_loss: 2.2812\n",
      "Epoch 10/10\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2.0889 - val_loss: 2.2813\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2.0889 - val_loss: 2.2813\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    validation_data=(X_test, y_test),\n",
    "    epochs=10,\n",
    "    batch_size=512\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b60fe135",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m160/160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
      "\u001b[1m160/160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
      "Accuracy score: 0.28975265017667845\n",
      "[[2.73877177e-02 1.96137875e-02 4.04827110e-02 3.47854160e-02\n",
      "  4.35889736e-02 5.07822679e-03 3.56469661e-01 4.64344397e-03\n",
      "  5.50785474e-02 1.82513837e-02 1.09947495e-01 1.10965565e-01\n",
      "  1.11318575e-02 1.62575141e-01]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  1.00000000e+00 0.00000000e+00 0.00000000e+00 9.51935274e-37\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  1.08502728e-28 1.01539040e-32]\n",
      " [1.25313923e-02 1.77367311e-02 2.32608709e-02 3.61891054e-02\n",
      "  7.55017698e-02 8.84305760e-02 1.59861341e-01 1.08172717e-02\n",
      "  5.12663014e-02 1.77868344e-02 1.20697394e-01 1.54913634e-01\n",
      "  1.23865157e-02 2.18620166e-01]\n",
      " [3.82742807e-02 2.89556831e-02 5.89071549e-02 4.01134342e-02\n",
      "  5.16922250e-02 4.35566576e-03 3.61135781e-01 6.34361710e-03\n",
      "  7.13731200e-02 2.13727970e-02 5.09148873e-02 6.93120658e-02\n",
      "  1.78774912e-02 1.79371819e-01]\n",
      " [3.00027728e-02 2.40007676e-02 3.65593359e-02 3.73587832e-02\n",
      "  4.14845273e-02 1.40442271e-02 2.09768295e-01 7.69879809e-03\n",
      "  6.80664256e-02 1.86122376e-02 2.09565967e-01 1.33277029e-01\n",
      "  6.38299109e-03 1.63177803e-01]]\n",
      "[ 6  4 13 ...  6 10  6]\n",
      "Accuracy score: 0.28975265017667845\n",
      "[[2.73877177e-02 1.96137875e-02 4.04827110e-02 3.47854160e-02\n",
      "  4.35889736e-02 5.07822679e-03 3.56469661e-01 4.64344397e-03\n",
      "  5.50785474e-02 1.82513837e-02 1.09947495e-01 1.10965565e-01\n",
      "  1.11318575e-02 1.62575141e-01]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  1.00000000e+00 0.00000000e+00 0.00000000e+00 9.51935274e-37\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  1.08502728e-28 1.01539040e-32]\n",
      " [1.25313923e-02 1.77367311e-02 2.32608709e-02 3.61891054e-02\n",
      "  7.55017698e-02 8.84305760e-02 1.59861341e-01 1.08172717e-02\n",
      "  5.12663014e-02 1.77868344e-02 1.20697394e-01 1.54913634e-01\n",
      "  1.23865157e-02 2.18620166e-01]\n",
      " [3.82742807e-02 2.89556831e-02 5.89071549e-02 4.01134342e-02\n",
      "  5.16922250e-02 4.35566576e-03 3.61135781e-01 6.34361710e-03\n",
      "  7.13731200e-02 2.13727970e-02 5.09148873e-02 6.93120658e-02\n",
      "  1.78774912e-02 1.79371819e-01]\n",
      " [3.00027728e-02 2.40007676e-02 3.65593359e-02 3.73587832e-02\n",
      "  4.14845273e-02 1.40442271e-02 2.09768295e-01 7.69879809e-03\n",
      "  6.80664256e-02 1.86122376e-02 2.09565967e-01 1.33277029e-01\n",
      "  6.38299109e-03 1.63177803e-01]]\n",
      "[ 6  4 13 ...  6 10  6]\n"
     ]
    }
   ],
   "source": [
    "#make predictions (will give a probability distribution)\n",
    "pred_hot = model.predict(X_test)\n",
    "#now pick the most likely outcome\n",
    "pred = np.argmax(pred_hot,axis=1)\n",
    "y_compare = np.argmax(y_test,axis=1) \n",
    "#calculate accuracy\n",
    "score = metrics.accuracy_score(y_compare, pred)\n",
    "\n",
    "print(\"Accuracy score: {}\".format(score))\n",
    "\n",
    "print(pred_hot[:5])\n",
    "print(pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c282b83",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e82b50b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m160/160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
      "\u001b[1m160/160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
      "                              precision    recall  f1-score   support\n",
      "\n",
      "       Anti-social behaviour       0.00      0.00      0.00       162\n",
      "               Bicycle theft       0.00      0.00      0.00       120\n",
      "                    Burglary       0.00      0.00      0.00       190\n",
      "   Criminal damage and arson       0.00      0.00      0.00       190\n",
      "                       Drugs       0.15      0.02      0.03       299\n",
      "                 Other crime       0.14      0.01      0.02       106\n",
      "                 Other theft       0.30      0.56      0.39      1119\n",
      "       Possession of weapons       0.00      0.00      0.00        44\n",
      "                Public order       0.00      0.00      0.00       345\n",
      "                     Robbery       0.00      0.00      0.00        95\n",
      "                 Shoplifting       0.42      0.43      0.42       685\n",
      "       Theft from the person       0.25      0.29      0.27       777\n",
      "               Vehicle crime       0.00      0.00      0.00        72\n",
      "Violence and sexual offences       0.24      0.36      0.29       890\n",
      "\n",
      "                    accuracy                           0.29      5094\n",
      "                   macro avg       0.11      0.12      0.10      5094\n",
      "                weighted avg       0.21      0.29      0.24      5094\n",
      "\n",
      "                              precision    recall  f1-score   support\n",
      "\n",
      "       Anti-social behaviour       0.00      0.00      0.00       162\n",
      "               Bicycle theft       0.00      0.00      0.00       120\n",
      "                    Burglary       0.00      0.00      0.00       190\n",
      "   Criminal damage and arson       0.00      0.00      0.00       190\n",
      "                       Drugs       0.15      0.02      0.03       299\n",
      "                 Other crime       0.14      0.01      0.02       106\n",
      "                 Other theft       0.30      0.56      0.39      1119\n",
      "       Possession of weapons       0.00      0.00      0.00        44\n",
      "                Public order       0.00      0.00      0.00       345\n",
      "                     Robbery       0.00      0.00      0.00        95\n",
      "                 Shoplifting       0.42      0.43      0.42       685\n",
      "       Theft from the person       0.25      0.29      0.27       777\n",
      "               Vehicle crime       0.00      0.00      0.00        72\n",
      "Violence and sexual offences       0.24      0.36      0.29       890\n",
      "\n",
      "                    accuracy                           0.29      5094\n",
      "                   macro avg       0.11      0.12      0.10      5094\n",
      "                weighted avg       0.21      0.29      0.24      5094\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/codespace/.local/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "/home/codespace/.local/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "/home/codespace/.local/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    }
   ],
   "source": [
    "# Predictions\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "y_true_classes = np.argmax(y_test, axis=1)\n",
    "\n",
    "# Classification Report\n",
    "print(classification_report(y_true_classes, y_pred_classes, target_names=encoder.classes_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "01e7b771",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sns' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[14]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      1\u001b[39m mat = confusion_matrix(pred, y_compare)\n\u001b[32m      3\u001b[39m \u001b[38;5;66;03m#using seaborn \u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m \u001b[43msns\u001b[49m.heatmap(mat, square=\u001b[38;5;28;01mTrue\u001b[39;00m, annot=\u001b[38;5;28;01mTrue\u001b[39;00m, cbar=\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m      5\u001b[39m plt.xlabel(\u001b[33m'\u001b[39m\u001b[33mpredicted value\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m      6\u001b[39m plt.ylabel(\u001b[33m'\u001b[39m\u001b[33mtrue value\u001b[39m\u001b[33m'\u001b[39m);\n",
      "\u001b[31mNameError\u001b[39m: name 'sns' is not defined"
     ]
    }
   ],
   "source": [
    "mat = confusion_matrix(pred, y_compare)\n",
    "\n",
    "#using seaborn \n",
    "sns.heatmap(mat, square=True, annot=True, cbar=False)\n",
    "plt.xlabel('predicted value')\n",
    "plt.ylabel('true value');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bb923fc",
   "metadata": {},
   "source": [
    "## Plot Training Curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6578eab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,5))\n",
    "plt.subplot(1,2,1)\n",
    "plt.plot(history.history['loss'], label='Train Loss')\n",
    "plt.plot(history.history['val_loss'], label='Val Loss')\n",
    "plt.legend(); plt.title('Loss')\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.plot(history.history['accuracy'], label='Train Acc')\n",
    "plt.plot(history.history['val_accuracy'], label='Val Acc')\n",
    "plt.legend(); plt.title('Accuracy')\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
