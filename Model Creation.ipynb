{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4dc324e1",
   "metadata": {},
   "source": [
    "# London Crime Conv1D Classifier\n",
    "Predicting **Crime type** using TensorFlow/Keras Conv1D Neural Network\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "baba850f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-04 20:58:51.734393: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-12-04 20:58:51.734763: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-12-04 20:58:51.782836: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-12-04 20:58:53.313762: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-12-04 20:58:53.314236: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-12-04 20:58:53.313762: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-12-04 20:58:53.314236: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n"
     ]
    }
   ],
   "source": [
    "# Libraries\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder, OneHotEncoder\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn import metrics\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Input, Dropout, BatchNormalization\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.optimizers import Adamax\n",
    "from tensorflow import keras\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3a46835",
   "metadata": {},
   "source": [
    "## Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9871ba64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Crime ID</th>\n",
       "      <th>Month</th>\n",
       "      <th>Reported by</th>\n",
       "      <th>Falls within</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Location</th>\n",
       "      <th>LSOA code</th>\n",
       "      <th>LSOA name</th>\n",
       "      <th>Crime type</th>\n",
       "      <th>Last outcome category</th>\n",
       "      <th>Context</th>\n",
       "      <th>source_file</th>\n",
       "      <th>source_folder</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5a10b2cf8fa37fbf3933f66319f1c2ce76ef9697e19442...</td>\n",
       "      <td>2024-12</td>\n",
       "      <td>City of London Police</td>\n",
       "      <td>City of London Police</td>\n",
       "      <td>-0.105965</td>\n",
       "      <td>51.518514</td>\n",
       "      <td>On or near Further/Higher Educational Building</td>\n",
       "      <td>E01000916</td>\n",
       "      <td>Camden 027B</td>\n",
       "      <td>Robbery</td>\n",
       "      <td>Investigation complete; no suspect identified</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2024-12-city-of-london-street.csv</td>\n",
       "      <td>datasets</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>71ac2a8e6b747e5044b1bb5e8b93b8b13a09bf39649390...</td>\n",
       "      <td>2024-12</td>\n",
       "      <td>City of London Police</td>\n",
       "      <td>City of London Police</td>\n",
       "      <td>-0.111596</td>\n",
       "      <td>51.518281</td>\n",
       "      <td>On or near Chancery Lane</td>\n",
       "      <td>E01000914</td>\n",
       "      <td>Camden 028B</td>\n",
       "      <td>Other theft</td>\n",
       "      <td>Investigation complete; no suspect identified</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2024-12-city-of-london-street.csv</td>\n",
       "      <td>datasets</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>e5dc3c4e04ebc5285c57dabef730c271df889665252ed9...</td>\n",
       "      <td>2024-12</td>\n",
       "      <td>City of London Police</td>\n",
       "      <td>City of London Police</td>\n",
       "      <td>-0.112096</td>\n",
       "      <td>51.515942</td>\n",
       "      <td>On or near Nightclub</td>\n",
       "      <td>E01000914</td>\n",
       "      <td>Camden 028B</td>\n",
       "      <td>Robbery</td>\n",
       "      <td>Status update unavailable</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2024-12-city-of-london-street.csv</td>\n",
       "      <td>datasets</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2072389e40234ffec9830716e10ba0aa4ad91fbe282bf5...</td>\n",
       "      <td>2024-12</td>\n",
       "      <td>City of London Police</td>\n",
       "      <td>City of London Police</td>\n",
       "      <td>-0.112537</td>\n",
       "      <td>51.519582</td>\n",
       "      <td>On or near Gray'S Inn Square</td>\n",
       "      <td>E01000914</td>\n",
       "      <td>Camden 028B</td>\n",
       "      <td>Shoplifting</td>\n",
       "      <td>Status update unavailable</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2024-12-city-of-london-street.csv</td>\n",
       "      <td>datasets</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5fe3737ddf7156d6fb68bb3a2b54dcb1f7bc354f5f70e9...</td>\n",
       "      <td>2024-12</td>\n",
       "      <td>City of London Police</td>\n",
       "      <td>City of London Police</td>\n",
       "      <td>-0.111596</td>\n",
       "      <td>51.518281</td>\n",
       "      <td>On or near Chancery Lane</td>\n",
       "      <td>E01000914</td>\n",
       "      <td>Camden 028B</td>\n",
       "      <td>Theft from the person</td>\n",
       "      <td>Investigation complete; no suspect identified</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2024-12-city-of-london-street.csv</td>\n",
       "      <td>datasets</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Crime ID    Month  \\\n",
       "0  5a10b2cf8fa37fbf3933f66319f1c2ce76ef9697e19442...  2024-12   \n",
       "1  71ac2a8e6b747e5044b1bb5e8b93b8b13a09bf39649390...  2024-12   \n",
       "2  e5dc3c4e04ebc5285c57dabef730c271df889665252ed9...  2024-12   \n",
       "3  2072389e40234ffec9830716e10ba0aa4ad91fbe282bf5...  2024-12   \n",
       "4  5fe3737ddf7156d6fb68bb3a2b54dcb1f7bc354f5f70e9...  2024-12   \n",
       "\n",
       "             Reported by           Falls within  Longitude   Latitude  \\\n",
       "0  City of London Police  City of London Police  -0.105965  51.518514   \n",
       "1  City of London Police  City of London Police  -0.111596  51.518281   \n",
       "2  City of London Police  City of London Police  -0.112096  51.515942   \n",
       "3  City of London Police  City of London Police  -0.112537  51.519582   \n",
       "4  City of London Police  City of London Police  -0.111596  51.518281   \n",
       "\n",
       "                                         Location  LSOA code    LSOA name  \\\n",
       "0  On or near Further/Higher Educational Building  E01000916  Camden 027B   \n",
       "1                        On or near Chancery Lane  E01000914  Camden 028B   \n",
       "2                            On or near Nightclub  E01000914  Camden 028B   \n",
       "3                    On or near Gray'S Inn Square  E01000914  Camden 028B   \n",
       "4                        On or near Chancery Lane  E01000914  Camden 028B   \n",
       "\n",
       "              Crime type                          Last outcome category  \\\n",
       "0                Robbery  Investigation complete; no suspect identified   \n",
       "1            Other theft  Investigation complete; no suspect identified   \n",
       "2                Robbery                      Status update unavailable   \n",
       "3            Shoplifting                      Status update unavailable   \n",
       "4  Theft from the person  Investigation complete; no suspect identified   \n",
       "\n",
       "   Context                        source_file source_folder  \n",
       "0      NaN  2024-12-city-of-london-street.csv      datasets  \n",
       "1      NaN  2024-12-city-of-london-street.csv      datasets  \n",
       "2      NaN  2024-12-city-of-london-street.csv      datasets  \n",
       "3      NaN  2024-12-city-of-london-street.csv      datasets  \n",
       "4      NaN  2024-12-city-of-london-street.csv      datasets  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('2022_2025_city_of_london_street.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a34f71f4",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b7e27c30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop duplicates rows\n",
    "df.drop_duplicates(inplace=True)\n",
    "\n",
    "# Drop the Crime ID, source column, and source file columns since they contain duplicate information/administrative purposes when merging the datasets, or are identifiers.\n",
    "df.drop(columns=['Crime ID', 'Context', 'source_file', 'source_folder'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7c506111",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Strip column names\n",
    "# REASON: In some cases, when reading CSV files, extra spaces can be inadvertently added in the column names.\n",
    "# This can lead to issues when trying to access these columns later in the code, as the names won't match exactly.\n",
    "df.columns = df.columns.str.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "923cd1b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Fill missing numeric values using KNN imputation, which in this case is the GPS coordinates (Longitude, Latitude)\n",
    "numeric_cols = ['Longitude', 'Latitude']\n",
    "imputer = KNNImputer(n_neighbors=5)\n",
    "# Note: For production, fit the imputer on the training set only to avoid data leakage.\n",
    "df[numeric_cols] = imputer.fit_transform(df[numeric_cols])\n",
    "\n",
    "# Encode target values, so that the crime ('Crime type') can be used for classification, (LABELS) to (NUMERICAL RANGE)\n",
    "target_col = 'Crime type'\n",
    "encoder = LabelEncoder()\n",
    "\n",
    "df['target_encoded'] = encoder.fit_transform(df[target_col])\n",
    "num_classes = df['target_encoded'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8d9dd549",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Features: numeric and categorical\n",
    "categorical_cols = ['Reported by', 'Falls within', 'LSOA code', 'LSOA name']\n",
    "df_encoded = pd.get_dummies(df[categorical_cols])\n",
    "\n",
    "X = pd.concat([df[numeric_cols], df_encoded], axis=1).values\n",
    "y = to_categorical(df['target_encoded'], num_classes=num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9a385267",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize numeric features\n",
    "scaler = StandardScaler()\n",
    "X[:, :len(numeric_cols)] = scaler.fit_transform(X[:, :len(numeric_cols)])\n",
    "\n",
    "X = X.astype(\"float32\")  # ensure proper dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fecf214d",
   "metadata": {},
   "source": [
    "## Train/Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "065846b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68d5b8d6",
   "metadata": {},
   "source": [
    "## Model Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "618cb2d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-04 20:58:57.163208: E external/local_xla/xla/stream_executor/cuda/cuda_platform.cc:51] failed call to cuInit: INTERNAL: CUDA error: Failed call to cuInit: UNKNOWN ERROR (303)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │        <span style=\"color: #00af00; text-decoration-color: #00af00\">24,960</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">650</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">154</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │        \u001b[38;5;34m24,960\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             │           \u001b[38;5;34m650\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m)             │           \u001b[38;5;34m154\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">77,294</span> (301.93 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m77,294\u001b[0m (301.93 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">25,764</span> (100.64 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m25,764\u001b[0m (100.64 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">51,530</span> (201.29 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m51,530\u001b[0m (201.29 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m160/160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
      "\u001b[1m160/160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
      "Accuracy score: 0.26442873969375735\n",
      "Accuracy score: 0.26442873969375735\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/Model/network.json'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 20\u001b[39m\n\u001b[32m     18\u001b[39m \u001b[38;5;66;03m# save neural network structure to JSON (no weights)\u001b[39;00m\n\u001b[32m     19\u001b[39m model_json = model.to_json()\n\u001b[32m---> \u001b[39m\u001b[32m20\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mos\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m.\u001b[49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43msave_path\u001b[49m\u001b[43m,\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mnetwork.json\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mw\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m json_file:\n\u001b[32m     21\u001b[39m     json_file.write(model_json)\n\u001b[32m     23\u001b[39m \u001b[38;5;66;03m# save entire network to HDF5 (save everything, suggested)\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.12/site-packages/IPython/core/interactiveshell.py:343\u001b[39m, in \u001b[36m_modified_open\u001b[39m\u001b[34m(file, *args, **kwargs)\u001b[39m\n\u001b[32m    336\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[32m0\u001b[39m, \u001b[32m1\u001b[39m, \u001b[32m2\u001b[39m}:\n\u001b[32m    337\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    338\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mIPython won\u001b[39m\u001b[33m'\u001b[39m\u001b[33mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m by default \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    339\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    340\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33myou can use builtins\u001b[39m\u001b[33m'\u001b[39m\u001b[33m open.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    341\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m343\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mio_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: '/Model/network.json'"
     ]
    }
   ],
   "source": [
    " \n",
    "model = Sequential()\n",
    "model.add(Input(X[1].shape))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(10))\n",
    "model.add(Dense(y.shape[1],activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam')\n",
    "model.fit(X_train,y_train,verbose=0,epochs=128)\n",
    "model.summary()\n",
    "pred = model.predict(X_test)\n",
    "pred = np.argmax(pred,axis=1)\n",
    "y_compare = np.argmax(y_test,axis=1) \n",
    "score = metrics.accuracy_score(y_compare, pred)\n",
    "print(\"Accuracy score: {}\".format(score))\n",
    "\n",
    "#path to where the file will be saved\n",
    "save_path = \"/Model/\"\n",
    "\n",
    "# save neural network structure to JSON (no weights)\n",
    "model_json = model.to_json()\n",
    "with open(os.path.join(save_path,\"network.json\"), \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "\n",
    "# save entire network to HDF5 (save everything, suggested)\n",
    "model.save(os.path.join(save_path,\"network.h5\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a9513f5",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a9c43281",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad9dd215",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    validation_data=(X_test, y_test),\n",
    "    epochs=10,\n",
    "    batch_size=512\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b60fe135",
   "metadata": {},
   "outputs": [],
   "source": [
    "#make predictions (will give a probability distribution)\n",
    "pred_hot = model.predict(X_test)\n",
    "#now pick the most likely outcome\n",
    "pred = np.argmax(pred_hot,axis=1)\n",
    "y_compare = np.argmax(y_test,axis=1) \n",
    "#calculate accuracy\n",
    "score = metrics.accuracy_score(y_compare, pred)\n",
    "\n",
    "print(\"Accuracy score: {}\".format(score))\n",
    "\n",
    "print(pred_hot[:5])\n",
    "print(pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c282b83",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e82b50b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predictions\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "y_true_classes = np.argmax(y_test, axis=1)\n",
    "\n",
    "# Classification Report\n",
    "print(classification_report(y_true_classes, y_pred_classes, target_names=encoder.classes_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01e7b771",
   "metadata": {},
   "outputs": [],
   "source": [
    "mat = confusion_matrix(pred, y_compare)\n",
    "\n",
    "#using seaborn \n",
    "sns.heatmap(mat, square=True, annot=True, cbar=False)\n",
    "plt.xlabel('predicted value')\n",
    "plt.ylabel('true value');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bb923fc",
   "metadata": {},
   "source": [
    "## Plot Training Curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6578eab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,5))\n",
    "plt.subplot(1,2,1)\n",
    "plt.plot(history.history['loss'], label='Train Loss')\n",
    "plt.plot(history.history['val_loss'], label='Val Loss')\n",
    "plt.legend(); plt.title('Loss')\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.plot(history.history['accuracy'], label='Train Acc')\n",
    "plt.plot(history.history['val_accuracy'], label='Val Acc')\n",
    "plt.legend(); plt.title('Accuracy')\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
