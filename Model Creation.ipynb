{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4dc324e1",
   "metadata": {},
   "source": [
    "# London Crime Conv1D Classifier\n",
    "Predicting **Crime type** using TensorFlow/Keras Conv1D Neural Network\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "baba850f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-04 18:55:00.446364: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-12-04 18:55:00.463617: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-12-04 18:55:02.464936: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-12-04 18:55:06.288664: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-12-04 18:55:06.289974: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n"
     ]
    }
   ],
   "source": [
    "# Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder, OneHotEncoder\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Input, Dropout, BatchNormalization\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.optimizers import Adamax\n",
    "from tensorflow import keras\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3a46835",
   "metadata": {},
   "source": [
    "## Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9871ba64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Crime ID</th>\n",
       "      <th>Month</th>\n",
       "      <th>Reported by</th>\n",
       "      <th>Falls within</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Location</th>\n",
       "      <th>LSOA code</th>\n",
       "      <th>LSOA name</th>\n",
       "      <th>Crime type</th>\n",
       "      <th>Last outcome category</th>\n",
       "      <th>Context</th>\n",
       "      <th>source_file</th>\n",
       "      <th>source_folder</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5a10b2cf8fa37fbf3933f66319f1c2ce76ef9697e19442...</td>\n",
       "      <td>2024-12</td>\n",
       "      <td>City of London Police</td>\n",
       "      <td>City of London Police</td>\n",
       "      <td>-0.105965</td>\n",
       "      <td>51.518514</td>\n",
       "      <td>On or near Further/Higher Educational Building</td>\n",
       "      <td>E01000916</td>\n",
       "      <td>Camden 027B</td>\n",
       "      <td>Robbery</td>\n",
       "      <td>Investigation complete; no suspect identified</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2024-12-city-of-london-street.csv</td>\n",
       "      <td>datasets</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>71ac2a8e6b747e5044b1bb5e8b93b8b13a09bf39649390...</td>\n",
       "      <td>2024-12</td>\n",
       "      <td>City of London Police</td>\n",
       "      <td>City of London Police</td>\n",
       "      <td>-0.111596</td>\n",
       "      <td>51.518281</td>\n",
       "      <td>On or near Chancery Lane</td>\n",
       "      <td>E01000914</td>\n",
       "      <td>Camden 028B</td>\n",
       "      <td>Other theft</td>\n",
       "      <td>Investigation complete; no suspect identified</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2024-12-city-of-london-street.csv</td>\n",
       "      <td>datasets</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>e5dc3c4e04ebc5285c57dabef730c271df889665252ed9...</td>\n",
       "      <td>2024-12</td>\n",
       "      <td>City of London Police</td>\n",
       "      <td>City of London Police</td>\n",
       "      <td>-0.112096</td>\n",
       "      <td>51.515942</td>\n",
       "      <td>On or near Nightclub</td>\n",
       "      <td>E01000914</td>\n",
       "      <td>Camden 028B</td>\n",
       "      <td>Robbery</td>\n",
       "      <td>Status update unavailable</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2024-12-city-of-london-street.csv</td>\n",
       "      <td>datasets</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2072389e40234ffec9830716e10ba0aa4ad91fbe282bf5...</td>\n",
       "      <td>2024-12</td>\n",
       "      <td>City of London Police</td>\n",
       "      <td>City of London Police</td>\n",
       "      <td>-0.112537</td>\n",
       "      <td>51.519582</td>\n",
       "      <td>On or near Gray'S Inn Square</td>\n",
       "      <td>E01000914</td>\n",
       "      <td>Camden 028B</td>\n",
       "      <td>Shoplifting</td>\n",
       "      <td>Status update unavailable</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2024-12-city-of-london-street.csv</td>\n",
       "      <td>datasets</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5fe3737ddf7156d6fb68bb3a2b54dcb1f7bc354f5f70e9...</td>\n",
       "      <td>2024-12</td>\n",
       "      <td>City of London Police</td>\n",
       "      <td>City of London Police</td>\n",
       "      <td>-0.111596</td>\n",
       "      <td>51.518281</td>\n",
       "      <td>On or near Chancery Lane</td>\n",
       "      <td>E01000914</td>\n",
       "      <td>Camden 028B</td>\n",
       "      <td>Theft from the person</td>\n",
       "      <td>Investigation complete; no suspect identified</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2024-12-city-of-london-street.csv</td>\n",
       "      <td>datasets</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Crime ID    Month  \\\n",
       "0  5a10b2cf8fa37fbf3933f66319f1c2ce76ef9697e19442...  2024-12   \n",
       "1  71ac2a8e6b747e5044b1bb5e8b93b8b13a09bf39649390...  2024-12   \n",
       "2  e5dc3c4e04ebc5285c57dabef730c271df889665252ed9...  2024-12   \n",
       "3  2072389e40234ffec9830716e10ba0aa4ad91fbe282bf5...  2024-12   \n",
       "4  5fe3737ddf7156d6fb68bb3a2b54dcb1f7bc354f5f70e9...  2024-12   \n",
       "\n",
       "             Reported by           Falls within  Longitude   Latitude  \\\n",
       "0  City of London Police  City of London Police  -0.105965  51.518514   \n",
       "1  City of London Police  City of London Police  -0.111596  51.518281   \n",
       "2  City of London Police  City of London Police  -0.112096  51.515942   \n",
       "3  City of London Police  City of London Police  -0.112537  51.519582   \n",
       "4  City of London Police  City of London Police  -0.111596  51.518281   \n",
       "\n",
       "                                         Location  LSOA code    LSOA name  \\\n",
       "0  On or near Further/Higher Educational Building  E01000916  Camden 027B   \n",
       "1                        On or near Chancery Lane  E01000914  Camden 028B   \n",
       "2                            On or near Nightclub  E01000914  Camden 028B   \n",
       "3                    On or near Gray'S Inn Square  E01000914  Camden 028B   \n",
       "4                        On or near Chancery Lane  E01000914  Camden 028B   \n",
       "\n",
       "              Crime type                          Last outcome category  \\\n",
       "0                Robbery  Investigation complete; no suspect identified   \n",
       "1            Other theft  Investigation complete; no suspect identified   \n",
       "2                Robbery                      Status update unavailable   \n",
       "3            Shoplifting                      Status update unavailable   \n",
       "4  Theft from the person  Investigation complete; no suspect identified   \n",
       "\n",
       "   Context                        source_file source_folder  \n",
       "0      NaN  2024-12-city-of-london-street.csv      datasets  \n",
       "1      NaN  2024-12-city-of-london-street.csv      datasets  \n",
       "2      NaN  2024-12-city-of-london-street.csv      datasets  \n",
       "3      NaN  2024-12-city-of-london-street.csv      datasets  \n",
       "4      NaN  2024-12-city-of-london-street.csv      datasets  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('2022_2025_city_of_london_street.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a34f71f4",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b7e27c30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop duplicates rows\n",
    "df.drop_duplicates(inplace=True)\n",
    "\n",
    "# Drop the Crime ID, source column, and source file columns since they contain duplicate information/administrative purposes when merging the datasets, or are identifiers.\n",
    "df.drop(columns=['Crime ID', 'Context', 'source_file', 'source_folder'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c506111",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Strip column names\n",
    "# REASON: In some cases, when reading CSV files, extra spaces can be inadvertently added in the column names.\n",
    "# This can lead to issues when trying to access these columns later in the code, as the names won't match exactly.\n",
    "df.columns = df.columns.str.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "923cd1b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Fill missing numeric values using KNN imputation, which in this case is the GPS coordinates (Longitude, Latitude)\n",
    "numeric_cols = ['Longitude', 'Latitude']\n",
    "imputer = KNNImputer(n_neighbors=5)\n",
    "# Note: For production, fit the imputer on the training set only to avoid data leakage.\n",
    "df[numeric_cols] = imputer.fit_transform(df[numeric_cols])\n",
    "\n",
    "# Encode target values, so that the crime ('Crime type') can be used for classification, (LABELS) to (NUMERICAL RANGE)\n",
    "target_col = 'Crime type'\n",
    "encoder = LabelEncoder()\n",
    "\n",
    "df['target_encoded'] = encoder.fit_transform(df[target_col])\n",
    "num_classes = df['target_encoded'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d9dd549",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Features: numeric and categorical\n",
    "categorical_cols = ['Reported by', 'Falls within', 'LSOA code', 'LSOA name']\n",
    "df_encoded = pd.get_dummies(df[categorical_cols])\n",
    "\n",
    "X = pd.concat([df[numeric_cols], df_encoded], axis=1).values\n",
    "y = to_categorical(df['target_encoded'], num_classes=num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a385267",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize numeric features\n",
    "scaler = StandardScaler()\n",
    "X[:, :len(numeric_cols)] = scaler.fit_transform(X[:, :len(numeric_cols)])\n",
    "\n",
    "X = X.astype(\"float32\")  # ensure proper dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fecf214d",
   "metadata": {},
   "source": [
    "## Train/Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "065846b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68d5b8d6",
   "metadata": {},
   "source": [
    "## Model Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "618cb2d2",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m input_shape = \u001b[43mX_train\u001b[49m.shape[\u001b[32m1\u001b[39m:]\n\u001b[32m      3\u001b[39m model = Sequential()\n\u001b[32m      4\u001b[39m model.add(Input(X[\u001b[32m1\u001b[39m].shape))\n",
      "\u001b[31mNameError\u001b[39m: name 'X_train' is not defined"
     ]
    }
   ],
   "source": [
    "input_shape = X_train.shape[1:]\n",
    " \n",
    "model = Sequential()\n",
    "model.add(Input(X[1].shape))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(10))\n",
    "model.add(Dense(y.shape[1],activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam')\n",
    "model.fit(X_train,y_train,verbose=0,epochs=128)\n",
    "model.summary()\n",
    "pred = model.predict(X_test)\n",
    "pred = np.argmax(pred,axis=1)\n",
    "y_compare = np.argmax(y_test,axis=1) \n",
    "score = metrics.accuracy_score(y_compare, pred)\n",
    "print(\"Accuracy score: {}\".format(score))\n",
    "\n",
    "#path to where the file will be saved\n",
    "save_path = \"/Model/\"\n",
    "\n",
    "# save neural network structure to JSON (no weights)\n",
    "model_json = model.to_json()\n",
    "with open(os.path.join(save_path,\"network.json\"), \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "\n",
    "# save entire network to HDF5 (save everything, suggested)\n",
    "model.save(os.path.join(save_path,\"network.h5\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9c43281",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad9dd215",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Invalid dtype: object",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[13]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m history = \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      2\u001b[39m \u001b[43m    \u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      3\u001b[39m \u001b[43m    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[43m=\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_test\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m10\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      5\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m512\u001b[39;49m\n\u001b[32m      6\u001b[39m \u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/python/3.12.1/lib/python3.12/site-packages/keras/src/utils/traceback_utils.py:122\u001b[39m, in \u001b[36mfilter_traceback.<locals>.error_handler\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    119\u001b[39m     filtered_tb = _process_traceback_frames(e.__traceback__)\n\u001b[32m    120\u001b[39m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[32m    121\u001b[39m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m122\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m e.with_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    123\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    124\u001b[39m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/python/3.12.1/lib/python3.12/site-packages/optree/ops.py:766\u001b[39m, in \u001b[36mtree_map\u001b[39m\u001b[34m(func, tree, is_leaf, none_is_leaf, namespace, *rests)\u001b[39m\n\u001b[32m    764\u001b[39m leaves, treespec = _C.flatten(tree, is_leaf, none_is_leaf, namespace)\n\u001b[32m    765\u001b[39m flat_args = [leaves] + [treespec.flatten_up_to(r) \u001b[38;5;28;01mfor\u001b[39;00m r \u001b[38;5;129;01min\u001b[39;00m rests]\n\u001b[32m--> \u001b[39m\u001b[32m766\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtreespec\u001b[49m\u001b[43m.\u001b[49m\u001b[43munflatten\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mmap\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43mflat_args\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mValueError\u001b[39m: Invalid dtype: object"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    validation_data=(X_test, y_test),\n",
    "    epochs=10,\n",
    "    batch_size=512\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b60fe135",
   "metadata": {},
   "outputs": [],
   "source": [
    "#make predictions (will give a probability distribution)\n",
    "pred_hot = model.predict(X_test)\n",
    "#now pick the most likely outcome\n",
    "pred = np.argmax(pred_hot,axis=1)\n",
    "y_compare = np.argmax(y_test,axis=1) \n",
    "#calculate accuracy\n",
    "score = metrics.accuracy_score(y_compare, pred)\n",
    "\n",
    "print(\"Accuracy score: {}\".format(score))\n",
    "\n",
    "print(pred_hot[:5])\n",
    "print(pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c282b83",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e82b50b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predictions\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "y_true_classes = np.argmax(y_test, axis=1)\n",
    "\n",
    "# Classification Report\n",
    "print(classification_report(y_true_classes, y_pred_classes, target_names=encoder.classes_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01e7b771",
   "metadata": {},
   "outputs": [],
   "source": [
    "mat = confusion_matrix(pred, y_compare)\n",
    "\n",
    "#using seaborn \n",
    "sns.heatmap(mat, square=True, annot=True, cbar=False)\n",
    "plt.xlabel('predicted value')\n",
    "plt.ylabel('true value');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bb923fc",
   "metadata": {},
   "source": [
    "## Plot Training Curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6578eab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,5))\n",
    "plt.subplot(1,2,1)\n",
    "plt.plot(history.history['loss'], label='Train Loss')\n",
    "plt.plot(history.history['val_loss'], label='Val Loss')\n",
    "plt.legend(); plt.title('Loss')\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.plot(history.history['accuracy'], label='Train Acc')\n",
    "plt.plot(history.history['val_accuracy'], label='Val Acc')\n",
    "plt.legend(); plt.title('Accuracy')\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
