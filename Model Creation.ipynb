{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4dc324e1",
   "metadata": {},
   "source": [
    "# London Crime Conv1D Classifier\n",
    "Predicting **Crime type** using TensorFlow/Keras Conv1D Neural Network\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "baba850f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-04 21:23:23.849413: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-12-04 21:23:23.849792: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-12-04 21:23:23.895791: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-12-04 21:23:25.326605: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-12-04 21:23:25.327108: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-12-04 21:23:25.326605: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-12-04 21:23:25.327108: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n"
     ]
    }
   ],
   "source": [
    "# Libraries\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder, OneHotEncoder\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn import metrics\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Input, Dropout, BatchNormalization\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.optimizers import Adamax\n",
    "from tensorflow import keras\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3a46835",
   "metadata": {},
   "source": [
    "## Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9871ba64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Crime ID</th>\n",
       "      <th>Month</th>\n",
       "      <th>Reported by</th>\n",
       "      <th>Falls within</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Location</th>\n",
       "      <th>LSOA code</th>\n",
       "      <th>LSOA name</th>\n",
       "      <th>Crime type</th>\n",
       "      <th>Last outcome category</th>\n",
       "      <th>Context</th>\n",
       "      <th>source_file</th>\n",
       "      <th>source_folder</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5a10b2cf8fa37fbf3933f66319f1c2ce76ef9697e19442...</td>\n",
       "      <td>2024-12</td>\n",
       "      <td>City of London Police</td>\n",
       "      <td>City of London Police</td>\n",
       "      <td>-0.105965</td>\n",
       "      <td>51.518514</td>\n",
       "      <td>On or near Further/Higher Educational Building</td>\n",
       "      <td>E01000916</td>\n",
       "      <td>Camden 027B</td>\n",
       "      <td>Robbery</td>\n",
       "      <td>Investigation complete; no suspect identified</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2024-12-city-of-london-street.csv</td>\n",
       "      <td>datasets</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>71ac2a8e6b747e5044b1bb5e8b93b8b13a09bf39649390...</td>\n",
       "      <td>2024-12</td>\n",
       "      <td>City of London Police</td>\n",
       "      <td>City of London Police</td>\n",
       "      <td>-0.111596</td>\n",
       "      <td>51.518281</td>\n",
       "      <td>On or near Chancery Lane</td>\n",
       "      <td>E01000914</td>\n",
       "      <td>Camden 028B</td>\n",
       "      <td>Other theft</td>\n",
       "      <td>Investigation complete; no suspect identified</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2024-12-city-of-london-street.csv</td>\n",
       "      <td>datasets</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>e5dc3c4e04ebc5285c57dabef730c271df889665252ed9...</td>\n",
       "      <td>2024-12</td>\n",
       "      <td>City of London Police</td>\n",
       "      <td>City of London Police</td>\n",
       "      <td>-0.112096</td>\n",
       "      <td>51.515942</td>\n",
       "      <td>On or near Nightclub</td>\n",
       "      <td>E01000914</td>\n",
       "      <td>Camden 028B</td>\n",
       "      <td>Robbery</td>\n",
       "      <td>Status update unavailable</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2024-12-city-of-london-street.csv</td>\n",
       "      <td>datasets</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2072389e40234ffec9830716e10ba0aa4ad91fbe282bf5...</td>\n",
       "      <td>2024-12</td>\n",
       "      <td>City of London Police</td>\n",
       "      <td>City of London Police</td>\n",
       "      <td>-0.112537</td>\n",
       "      <td>51.519582</td>\n",
       "      <td>On or near Gray'S Inn Square</td>\n",
       "      <td>E01000914</td>\n",
       "      <td>Camden 028B</td>\n",
       "      <td>Shoplifting</td>\n",
       "      <td>Status update unavailable</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2024-12-city-of-london-street.csv</td>\n",
       "      <td>datasets</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5fe3737ddf7156d6fb68bb3a2b54dcb1f7bc354f5f70e9...</td>\n",
       "      <td>2024-12</td>\n",
       "      <td>City of London Police</td>\n",
       "      <td>City of London Police</td>\n",
       "      <td>-0.111596</td>\n",
       "      <td>51.518281</td>\n",
       "      <td>On or near Chancery Lane</td>\n",
       "      <td>E01000914</td>\n",
       "      <td>Camden 028B</td>\n",
       "      <td>Theft from the person</td>\n",
       "      <td>Investigation complete; no suspect identified</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2024-12-city-of-london-street.csv</td>\n",
       "      <td>datasets</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Crime ID    Month  \\\n",
       "0  5a10b2cf8fa37fbf3933f66319f1c2ce76ef9697e19442...  2024-12   \n",
       "1  71ac2a8e6b747e5044b1bb5e8b93b8b13a09bf39649390...  2024-12   \n",
       "2  e5dc3c4e04ebc5285c57dabef730c271df889665252ed9...  2024-12   \n",
       "3  2072389e40234ffec9830716e10ba0aa4ad91fbe282bf5...  2024-12   \n",
       "4  5fe3737ddf7156d6fb68bb3a2b54dcb1f7bc354f5f70e9...  2024-12   \n",
       "\n",
       "             Reported by           Falls within  Longitude   Latitude  \\\n",
       "0  City of London Police  City of London Police  -0.105965  51.518514   \n",
       "1  City of London Police  City of London Police  -0.111596  51.518281   \n",
       "2  City of London Police  City of London Police  -0.112096  51.515942   \n",
       "3  City of London Police  City of London Police  -0.112537  51.519582   \n",
       "4  City of London Police  City of London Police  -0.111596  51.518281   \n",
       "\n",
       "                                         Location  LSOA code    LSOA name  \\\n",
       "0  On or near Further/Higher Educational Building  E01000916  Camden 027B   \n",
       "1                        On or near Chancery Lane  E01000914  Camden 028B   \n",
       "2                            On or near Nightclub  E01000914  Camden 028B   \n",
       "3                    On or near Gray'S Inn Square  E01000914  Camden 028B   \n",
       "4                        On or near Chancery Lane  E01000914  Camden 028B   \n",
       "\n",
       "              Crime type                          Last outcome category  \\\n",
       "0                Robbery  Investigation complete; no suspect identified   \n",
       "1            Other theft  Investigation complete; no suspect identified   \n",
       "2                Robbery                      Status update unavailable   \n",
       "3            Shoplifting                      Status update unavailable   \n",
       "4  Theft from the person  Investigation complete; no suspect identified   \n",
       "\n",
       "   Context                        source_file source_folder  \n",
       "0      NaN  2024-12-city-of-london-street.csv      datasets  \n",
       "1      NaN  2024-12-city-of-london-street.csv      datasets  \n",
       "2      NaN  2024-12-city-of-london-street.csv      datasets  \n",
       "3      NaN  2024-12-city-of-london-street.csv      datasets  \n",
       "4      NaN  2024-12-city-of-london-street.csv      datasets  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('2022_2025_city_of_london_street.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a34f71f4",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b7e27c30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop duplicates rows\n",
    "df.drop_duplicates(inplace=True)\n",
    "\n",
    "# Drop the Crime ID, source column, and source file columns since they contain duplicate information/administrative purposes when merging the datasets, or are identifiers.\n",
    "df.drop(columns=['Crime ID', 'Context', 'source_file', 'source_folder'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7c506111",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Strip column names\n",
    "# REASON: In some cases, when reading CSV files, extra spaces can be inadvertently added in the column names.\n",
    "# This can lead to issues when trying to access these columns later in the code, as the names won't match exactly.\n",
    "df.columns = df.columns.str.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "923cd1b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Fill missing numeric values using KNN imputation, which in this case is the GPS coordinates (Longitude, Latitude)\n",
    "numeric_cols = ['Longitude', 'Latitude']\n",
    "imputer = KNNImputer(n_neighbors=5)\n",
    "# Note: For production, fit the imputer on the training set only to avoid data leakage.\n",
    "df[numeric_cols] = imputer.fit_transform(df[numeric_cols])\n",
    "\n",
    "# Encode target values, so that the crime ('Crime type') can be used for classification, (LABELS) to (NUMERICAL RANGE)\n",
    "target_col = 'Crime type'\n",
    "encoder = LabelEncoder()\n",
    "\n",
    "df['target_encoded'] = encoder.fit_transform(df[target_col])\n",
    "num_classes = df['target_encoded'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8d9dd549",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Features: numeric and categorical\n",
    "categorical_cols = ['Reported by', 'Falls within', 'LSOA code', 'LSOA name']\n",
    "df_encoded = pd.get_dummies(df[categorical_cols])\n",
    "\n",
    "X = pd.concat([df[numeric_cols], df_encoded], axis=1).values\n",
    "y = to_categorical(df['target_encoded'], num_classes=num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9a385267",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize numeric features\n",
    "scaler = StandardScaler()\n",
    "X[:, :len(numeric_cols)] = scaler.fit_transform(X[:, :len(numeric_cols)])\n",
    "\n",
    "X = X.astype(\"float32\")  # ensure proper dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fecf214d",
   "metadata": {},
   "source": [
    "## Train/Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "065846b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68d5b8d6",
   "metadata": {},
   "source": [
    "## Model Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "618cb2d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-04 21:23:29.137849: E external/local_xla/xla/stream_executor/cuda/cuda_platform.cc:51] failed call to cuInit: INTERNAL: CUDA error: Failed call to cuInit: UNKNOWN ERROR (303)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 7\u001b[39m\n\u001b[32m      5\u001b[39m model.add(Dense(y.shape[\u001b[32m1\u001b[39m],activation=\u001b[33m'\u001b[39m\u001b[33msoftmax\u001b[39m\u001b[33m'\u001b[39m))\n\u001b[32m      6\u001b[39m model.compile(loss=\u001b[33m'\u001b[39m\u001b[33mcategorical_crossentropy\u001b[39m\u001b[33m'\u001b[39m, optimizer=\u001b[33m'\u001b[39m\u001b[33madam\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m128\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      8\u001b[39m model.summary()\n\u001b[32m      9\u001b[39m pred = model.predict(X_test)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/python/3.12.1/lib/python3.12/site-packages/keras/src/utils/traceback_utils.py:117\u001b[39m, in \u001b[36mfilter_traceback.<locals>.error_handler\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    115\u001b[39m filtered_tb = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    116\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m117\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    118\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    119\u001b[39m     filtered_tb = _process_traceback_frames(e.__traceback__)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/python/3.12.1/lib/python3.12/site-packages/keras/src/backend/tensorflow/trainer.py:397\u001b[39m, in \u001b[36mTensorFlowTrainer.fit\u001b[39m\u001b[34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[39m\n\u001b[32m    395\u001b[39m callbacks.on_epoch_begin(epoch)\n\u001b[32m    396\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m epoch_iterator.catch_stop_iteration():\n\u001b[32m--> \u001b[39m\u001b[32m397\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mbegin_step\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mend_step\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43miterator\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mepoch_iterator\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    398\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m.\u001b[49m\u001b[43mon_train_batch_begin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbegin_step\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    399\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlogs\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/python/3.12.1/lib/python3.12/site-packages/keras/src/backend/tensorflow/trainer.py:764\u001b[39m, in \u001b[36mTFEpochIterator.__next__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    763\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__next__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m764\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_epoch_iterator\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/python/3.12.1/lib/python3.12/site-packages/keras/src/trainers/epoch_iterator.py:125\u001b[39m, in \u001b[36mEpochIterator._enumerate_iterator\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    119\u001b[39m         \u001b[38;5;28;01myield\u001b[39;00m (\n\u001b[32m    120\u001b[39m             step,\n\u001b[32m    121\u001b[39m             step + \u001b[38;5;28mself\u001b[39m.steps_per_execution - \u001b[32m1\u001b[39m,\n\u001b[32m    122\u001b[39m             \u001b[38;5;28mself\u001b[39m._current_iterator,\n\u001b[32m    123\u001b[39m         )\n\u001b[32m    124\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._num_batches \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._steps_seen >= \u001b[38;5;28mself\u001b[39m._num_batches:\n\u001b[32m--> \u001b[39m\u001b[32m125\u001b[39m         \u001b[38;5;28mself\u001b[39m._current_iterator = \u001b[38;5;28;43miter\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_get_iterator\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    126\u001b[39m         \u001b[38;5;28mself\u001b[39m._steps_seen = \u001b[32m0\u001b[39m\n\u001b[32m    127\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/python/3.12.1/lib/python3.12/site-packages/tensorflow/python/data/ops/dataset_ops.py:501\u001b[39m, in \u001b[36mDatasetV2.__iter__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    499\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m context.executing_eagerly() \u001b[38;5;129;01mor\u001b[39;00m ops.inside_function():\n\u001b[32m    500\u001b[39m   \u001b[38;5;28;01mwith\u001b[39;00m ops.colocate_with(\u001b[38;5;28mself\u001b[39m._variant_tensor):\n\u001b[32m--> \u001b[39m\u001b[32m501\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43miterator_ops\u001b[49m\u001b[43m.\u001b[49m\u001b[43mOwnedIterator\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    502\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    503\u001b[39m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33m`tf.data.Dataset` only supports Python-style \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    504\u001b[39m                      \u001b[33m\"\u001b[39m\u001b[33miteration in eager mode or within tf.function.\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/python/3.12.1/lib/python3.12/site-packages/tensorflow/python/data/ops/iterator_ops.py:709\u001b[39m, in \u001b[36mOwnedIterator.__init__\u001b[39m\u001b[34m(self, dataset, components, element_spec)\u001b[39m\n\u001b[32m    705\u001b[39m   \u001b[38;5;28;01mif\u001b[39;00m (components \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m element_spec \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[32m    706\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    707\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mWhen `dataset` is provided, `element_spec` and `components` must \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    708\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mnot be specified.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m709\u001b[39m   \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_create_iterator\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    711\u001b[39m \u001b[38;5;28mself\u001b[39m._get_next_call_count = \u001b[32m0\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/python/3.12.1/lib/python3.12/site-packages/tensorflow/python/data/ops/iterator_ops.py:748\u001b[39m, in \u001b[36mOwnedIterator._create_iterator\u001b[39m\u001b[34m(self, dataset)\u001b[39m\n\u001b[32m    745\u001b[39m   \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(fulltype.args[\u001b[32m0\u001b[39m].args[\u001b[32m0\u001b[39m].args) == \u001b[38;5;28mlen\u001b[39m(\n\u001b[32m    746\u001b[39m       \u001b[38;5;28mself\u001b[39m._flat_output_types)\n\u001b[32m    747\u001b[39m   \u001b[38;5;28mself\u001b[39m._iterator_resource.op.experimental_set_type(fulltype)\n\u001b[32m--> \u001b[39m\u001b[32m748\u001b[39m \u001b[43mgen_dataset_ops\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmake_iterator\u001b[49m\u001b[43m(\u001b[49m\u001b[43mds_variant\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_iterator_resource\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/python/3.12.1/lib/python3.12/site-packages/tensorflow/python/ops/gen_dataset_ops.py:3478\u001b[39m, in \u001b[36mmake_iterator\u001b[39m\u001b[34m(dataset, iterator, name)\u001b[39m\n\u001b[32m   3476\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m tld.is_eager:\n\u001b[32m   3477\u001b[39m   \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m3478\u001b[39m     _result = \u001b[43mpywrap_tfe\u001b[49m\u001b[43m.\u001b[49m\u001b[43mTFE_Py_FastPathExecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   3479\u001b[39m \u001b[43m      \u001b[49m\u001b[43m_ctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mMakeIterator\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3480\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m _result\n\u001b[32m   3481\u001b[39m   \u001b[38;5;28;01mexcept\u001b[39;00m _core._NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    " \n",
    "model = Sequential()\n",
    "model.add(Input(X[1].shape))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(10))\n",
    "model.add(Dense(y.shape[1],activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam')\n",
    "model.fit(X_train,y_train,verbose=0,epochs=128)\n",
    "model.summary()\n",
    "pred = model.predict(X_test)\n",
    "pred = np.argmax(pred,axis=1)\n",
    "y_compare = np.argmax(y_test,axis=1) \n",
    "score = metrics.accuracy_score(y_compare, pred)\n",
    "print(\"Accuracy score: {}\".format(score))\n",
    "\n",
    "#path to where the file will be saved\n",
    "save_path = \"Model\"\n",
    "\n",
    "# save neural network structure to JSON (no weights)\n",
    "model_json = model.to_json()\n",
    "with open(os.path.join(save_path,\"network.json\"), \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "\n",
    "# save entire network to HDF5 (save everything, suggested)\n",
    "model.save(os.path.join(save_path,\"network.h5\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a9513f5",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a9c43281",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad9dd215",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 2.0935 - val_loss: 2.2786\n",
      "Epoch 2/10\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 2.0935 - val_loss: 2.2786\n",
      "Epoch 2/10\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2.0904 - val_loss: 2.2782\n",
      "Epoch 3/10\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2.0904 - val_loss: 2.2782\n",
      "Epoch 3/10\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2.0899 - val_loss: 2.2794\n",
      "Epoch 4/10\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2.0899 - val_loss: 2.2794\n",
      "Epoch 4/10\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2.0898 - val_loss: 2.2795\n",
      "Epoch 5/10\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2.0898 - val_loss: 2.2795\n",
      "Epoch 5/10\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2.0894 - val_loss: 2.2802\n",
      "Epoch 6/10\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2.0894 - val_loss: 2.2802\n",
      "Epoch 6/10\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2.0894 - val_loss: 2.2802\n",
      "Epoch 7/10\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2.0894 - val_loss: 2.2802\n",
      "Epoch 7/10\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2.0894 - val_loss: 2.2808\n",
      "Epoch 8/10\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2.0894 - val_loss: 2.2808\n",
      "Epoch 8/10\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2.0891 - val_loss: 2.2806\n",
      "Epoch 9/10\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2.0891 - val_loss: 2.2806\n",
      "Epoch 9/10\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2.0892 - val_loss: 2.2812\n",
      "Epoch 10/10\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2.0892 - val_loss: 2.2812\n",
      "Epoch 10/10\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2.0889 - val_loss: 2.2813\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2.0889 - val_loss: 2.2813\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    validation_data=(X_test, y_test),\n",
    "    epochs=10,\n",
    "    batch_size=512\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b60fe135",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m160/160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
      "\u001b[1m160/160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
      "Accuracy score: 0.28975265017667845\n",
      "[[2.73877177e-02 1.96137875e-02 4.04827110e-02 3.47854160e-02\n",
      "  4.35889736e-02 5.07822679e-03 3.56469661e-01 4.64344397e-03\n",
      "  5.50785474e-02 1.82513837e-02 1.09947495e-01 1.10965565e-01\n",
      "  1.11318575e-02 1.62575141e-01]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  1.00000000e+00 0.00000000e+00 0.00000000e+00 9.51935274e-37\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  1.08502728e-28 1.01539040e-32]\n",
      " [1.25313923e-02 1.77367311e-02 2.32608709e-02 3.61891054e-02\n",
      "  7.55017698e-02 8.84305760e-02 1.59861341e-01 1.08172717e-02\n",
      "  5.12663014e-02 1.77868344e-02 1.20697394e-01 1.54913634e-01\n",
      "  1.23865157e-02 2.18620166e-01]\n",
      " [3.82742807e-02 2.89556831e-02 5.89071549e-02 4.01134342e-02\n",
      "  5.16922250e-02 4.35566576e-03 3.61135781e-01 6.34361710e-03\n",
      "  7.13731200e-02 2.13727970e-02 5.09148873e-02 6.93120658e-02\n",
      "  1.78774912e-02 1.79371819e-01]\n",
      " [3.00027728e-02 2.40007676e-02 3.65593359e-02 3.73587832e-02\n",
      "  4.14845273e-02 1.40442271e-02 2.09768295e-01 7.69879809e-03\n",
      "  6.80664256e-02 1.86122376e-02 2.09565967e-01 1.33277029e-01\n",
      "  6.38299109e-03 1.63177803e-01]]\n",
      "[ 6  4 13 ...  6 10  6]\n",
      "Accuracy score: 0.28975265017667845\n",
      "[[2.73877177e-02 1.96137875e-02 4.04827110e-02 3.47854160e-02\n",
      "  4.35889736e-02 5.07822679e-03 3.56469661e-01 4.64344397e-03\n",
      "  5.50785474e-02 1.82513837e-02 1.09947495e-01 1.10965565e-01\n",
      "  1.11318575e-02 1.62575141e-01]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  1.00000000e+00 0.00000000e+00 0.00000000e+00 9.51935274e-37\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  1.08502728e-28 1.01539040e-32]\n",
      " [1.25313923e-02 1.77367311e-02 2.32608709e-02 3.61891054e-02\n",
      "  7.55017698e-02 8.84305760e-02 1.59861341e-01 1.08172717e-02\n",
      "  5.12663014e-02 1.77868344e-02 1.20697394e-01 1.54913634e-01\n",
      "  1.23865157e-02 2.18620166e-01]\n",
      " [3.82742807e-02 2.89556831e-02 5.89071549e-02 4.01134342e-02\n",
      "  5.16922250e-02 4.35566576e-03 3.61135781e-01 6.34361710e-03\n",
      "  7.13731200e-02 2.13727970e-02 5.09148873e-02 6.93120658e-02\n",
      "  1.78774912e-02 1.79371819e-01]\n",
      " [3.00027728e-02 2.40007676e-02 3.65593359e-02 3.73587832e-02\n",
      "  4.14845273e-02 1.40442271e-02 2.09768295e-01 7.69879809e-03\n",
      "  6.80664256e-02 1.86122376e-02 2.09565967e-01 1.33277029e-01\n",
      "  6.38299109e-03 1.63177803e-01]]\n",
      "[ 6  4 13 ...  6 10  6]\n"
     ]
    }
   ],
   "source": [
    "#make predictions (will give a probability distribution)\n",
    "pred_hot = model.predict(X_test)\n",
    "#now pick the most likely outcome\n",
    "pred = np.argmax(pred_hot,axis=1)\n",
    "y_compare = np.argmax(y_test,axis=1) \n",
    "#calculate accuracy\n",
    "score = metrics.accuracy_score(y_compare, pred)\n",
    "\n",
    "print(\"Accuracy score: {}\".format(score))\n",
    "\n",
    "print(pred_hot[:5])\n",
    "print(pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c282b83",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e82b50b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m160/160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
      "\u001b[1m160/160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
      "                              precision    recall  f1-score   support\n",
      "\n",
      "       Anti-social behaviour       0.00      0.00      0.00       162\n",
      "               Bicycle theft       0.00      0.00      0.00       120\n",
      "                    Burglary       0.00      0.00      0.00       190\n",
      "   Criminal damage and arson       0.00      0.00      0.00       190\n",
      "                       Drugs       0.15      0.02      0.03       299\n",
      "                 Other crime       0.14      0.01      0.02       106\n",
      "                 Other theft       0.30      0.56      0.39      1119\n",
      "       Possession of weapons       0.00      0.00      0.00        44\n",
      "                Public order       0.00      0.00      0.00       345\n",
      "                     Robbery       0.00      0.00      0.00        95\n",
      "                 Shoplifting       0.42      0.43      0.42       685\n",
      "       Theft from the person       0.25      0.29      0.27       777\n",
      "               Vehicle crime       0.00      0.00      0.00        72\n",
      "Violence and sexual offences       0.24      0.36      0.29       890\n",
      "\n",
      "                    accuracy                           0.29      5094\n",
      "                   macro avg       0.11      0.12      0.10      5094\n",
      "                weighted avg       0.21      0.29      0.24      5094\n",
      "\n",
      "                              precision    recall  f1-score   support\n",
      "\n",
      "       Anti-social behaviour       0.00      0.00      0.00       162\n",
      "               Bicycle theft       0.00      0.00      0.00       120\n",
      "                    Burglary       0.00      0.00      0.00       190\n",
      "   Criminal damage and arson       0.00      0.00      0.00       190\n",
      "                       Drugs       0.15      0.02      0.03       299\n",
      "                 Other crime       0.14      0.01      0.02       106\n",
      "                 Other theft       0.30      0.56      0.39      1119\n",
      "       Possession of weapons       0.00      0.00      0.00        44\n",
      "                Public order       0.00      0.00      0.00       345\n",
      "                     Robbery       0.00      0.00      0.00        95\n",
      "                 Shoplifting       0.42      0.43      0.42       685\n",
      "       Theft from the person       0.25      0.29      0.27       777\n",
      "               Vehicle crime       0.00      0.00      0.00        72\n",
      "Violence and sexual offences       0.24      0.36      0.29       890\n",
      "\n",
      "                    accuracy                           0.29      5094\n",
      "                   macro avg       0.11      0.12      0.10      5094\n",
      "                weighted avg       0.21      0.29      0.24      5094\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/codespace/.local/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "/home/codespace/.local/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "/home/codespace/.local/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    }
   ],
   "source": [
    "# Predictions\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "y_true_classes = np.argmax(y_test, axis=1)\n",
    "\n",
    "# Classification Report\n",
    "print(classification_report(y_true_classes, y_pred_classes, target_names=encoder.classes_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01e7b771",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sns' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[14]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      1\u001b[39m mat = confusion_matrix(pred, y_compare)\n\u001b[32m      3\u001b[39m \u001b[38;5;66;03m#using seaborn \u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m \u001b[43msns\u001b[49m.heatmap(mat, square=\u001b[38;5;28;01mTrue\u001b[39;00m, annot=\u001b[38;5;28;01mTrue\u001b[39;00m, cbar=\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m      5\u001b[39m plt.xlabel(\u001b[33m'\u001b[39m\u001b[33mpredicted value\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m      6\u001b[39m plt.ylabel(\u001b[33m'\u001b[39m\u001b[33mtrue value\u001b[39m\u001b[33m'\u001b[39m);\n",
      "\u001b[31mNameError\u001b[39m: name 'sns' is not defined"
     ]
    }
   ],
   "source": [
    "mat = confusion_matrix(pred, y_compare)\n",
    "\n",
    "#using seaborn \n",
    "sns.heatmap(mat, square=True, annot=True, cbar=False)\n",
    "plt.xlabel('predicted value')\n",
    "plt.ylabel('true value');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bb923fc",
   "metadata": {},
   "source": [
    "## Plot Training Curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6578eab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,5))\n",
    "plt.subplot(1,2,1)\n",
    "plt.plot(history.history['loss'], label='Train Loss')\n",
    "plt.plot(history.history['val_loss'], label='Val Loss')\n",
    "plt.legend(); plt.title('Loss')\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.plot(history.history['accuracy'], label='Train Acc')\n",
    "plt.plot(history.history['val_accuracy'], label='Val Acc')\n",
    "plt.legend(); plt.title('Accuracy')\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
